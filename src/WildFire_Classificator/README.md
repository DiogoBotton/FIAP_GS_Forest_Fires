# üöí Classificador de Queimadas (CNN)

Projeto de classifica√ß√£o de imagens em duas categorias:  
- **`fire`** (queimada)  
- **`no_fire`** (n√£o queimada)

## üîç Descri√ß√£o

Este projeto implementa e compara tr√™s abordagens de Deep Learning para detectar queimadas em imagens:

1. **CNN treinada do zero** ‚Äì arquitetura customizada e treinada em ~10 √©pocas.  
2. **Transfer Learning** ‚Äì utilizando InceptionV3 pr√©-treinado no ImageNet.  
3. **Fine-Tuning** ‚Äì refinamento do modelo pr√©-treinado em nosso conjunto de dados.

O objetivo √© avaliar acur√°cia, generaliza√ß√£o e custo computacional de cada abordagem.

## üìä Resultados

## Resultados da CNN Treinada do Zero

- Acur√°cia (test): 94%
- Precision/Recall/F1 (classe 0): 0.88 / 0.95 / 0.91
- Precision/Recall/F1 (classe 1): 0.98 / 0.93 / 0.96

Observa√ß√£o: sinais claros de overfitting (train_loss‚Üí0 vs val_loss‚âà0.10).

### Gr√°ficos de Acur√°cia e Perda

![Acur√°cia por √©poca](readme-imgs/cnn_zero_acuracia_por_epoca.png)

![Perda por √©poca](readme-imgs/cnn_zero_perda_por_epoca.png)

## Resultados da Transfer√™ncia de Aprendizado

- Acur√°cia (test): 100%
- Precision/Recall/F1 (ambas classes): 1.00

Observa√ß√£o: excelente generaliza√ß√£o, mas maior custo computacional.

![Acur√°cia por √©poca](readme-imgs/cnn_zero_acuracia_por_epoca.png)

![Perda por √©poca](readme-imgs/cnn_zero_perda_por_epoca.png)


# Interpreta√ß√£o do Fine-Tuning

- Acur√°cia (test): 100%
- Precision/Recall/F1 (ambas classes): 1.00

Observa√ß√£o: treinamento interrompido em 11/50 √©pocas via EarlyStopping.
Este documento traz a an√°lise dos resultados obtidos ap√≥s o fine-tuning do modelo de classifica√ß√£o de imagens de queimadas.


![Acur√°cia por √©poca](readme-imgs/accuracy_per_epoch.png)  


## üìù Conclus√µes e Pr√≥ximos Passos

Melhor abordagem: Transfer Learning e Fine-Tuning superaram CNN do zero em acur√°cia e generaliza√ß√£o.

Overfitting (CNN do zero):

- Adicionar data augmentation
- Incluir Dropout e BatchNormalization
- Aumentar volume de dados ou usar valida√ß√£o cruzada

Hyperparam tuning: explorar learning_rate, batch_size e callbacks (EarlyStopping, ReduceLROnPlateau)

Escalabilidade: converter Fine-Tuning para TinyML no ESP32-CAM para infer√™ncia embarcada
