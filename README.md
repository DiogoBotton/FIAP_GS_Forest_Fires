# FIAP - Faculdade de Inform√°tica e Administra√ß√£o Paulista
Projeto voltado a desenvolver solu√ß√µes com Redes Neurais Convolucionais (CNN) e Redes Recorrentes abordando problemas de s√©ries temporais.

<p align="center">
<a href= "https://www.fiap.com.br/"><img src="assets/logo-fiap.png" alt="FIAP - Faculdade de Inform√°tica e Admnistra√ß√£o Paulista" border="0" width=40% height=40%></a>
</p>

<br>

# Nome do projeto
Monitoramento de Queimadas via Vis√£o Computacional e Previs√£o de Focos de Inc√™ndio a Partir de An√°lises de S√©ries Temporais

## üë®‚Äçüéì Integrantes: 
- <a href="https://www.linkedin.com/in/bryanjfagundes/">Bryan Fagundes</a>
- <a href="https://br.linkedin.com/in/brenner-fagundes">Brenner Fagundes</a>
- <a href="https://www.linkedin.com/in/diogo-botton-46ba49197/">Diogo Botton</a> 
- <a href="https://www.linkedin.com/in/hyankacoelho/">Hyanka Coelho</a> 
- <a href="https://www.linkedin.com/in/julianahungaro/">Juliana Hungaro Fidelis</a>

## üë©‚Äçüè´ Professores:
### Tutor(a) 
- <a href="https://www.linkedin.com/in/leonardoorabona?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app">Leonardo Ruiz Orabona</a>
### Coordenador(a)
- <a href="https://www.linkedin.com/in/andregodoichiovato/">Andr√© Godoi</a>

## üìú Descri√ß√£o

A fazer...

## üìÅ Estrutura de pastas

Dentre os arquivos e pastas presentes na raiz do projeto, definem-se:

- <b>src</b>: Todo o c√≥digo fonte criado. (Complementar)

## üîß Como executar o c√≥digo

A fazer...


Modelo de classifica√ß√£o de queimada (CNN)
Problema: classificar imagens em 'fire' vs. 'no fire'

fire (queimada)
no fire (n√ßao queimada)

## Resultados da CNN Treinada do Zero

### Vis√£o Geral

Este modelo foi treinado do zero para classificar imagens em duas categorias: "fire" (fogo) e "no fire" (sem fogo). O objetivo era criar um modelo base para comparar com abordagens de Transfer Learning e Fine-Tuning.

### Desempenho Durante o Treinamento

O modelo mostrou um r√°pido aumento na acur√°cia durante as primeiras √©pocas, com sinais de overfitting √† medida que o treinamento avan√ßava.

*   **Acur√°cia:** A acur√°cia no conjunto de treinamento atingiu quase 100% ao final das 10 √©pocas, enquanto a acur√°cia no conjunto de valida√ß√£o se estabilizou em torno de 95-97%.
*   **Perda (Loss):** A perda no conjunto de treinamento diminuiu para perto de zero, enquanto a perda no conjunto de valida√ß√£o permaneceu acima de 0.10, indicando overfitting.

### Gr√°ficos de Acur√°cia e Perda

![Acur√°cia por √©poca](assets/cnn_zero_acuracia_por_epoca)


*Este gr√°fico mostra a acur√°cia ao longo das √©pocas para os conjuntos de treinamento e valida√ß√£o.*

![Perda por √©poca](assets/cnn_zero_perda_por_epoca)

*Este gr√°fico exibe a perda (loss) ao longo das √©pocas para os conjuntos de treinamento e valida√ß√£o.*

### Matriz de Confus√£o

![Matriz de Confus√£o](assets/cnn_zero_matriz_confusao)

A matriz de confus√£o revela o seguinte:

*   **Classe "no fire":** 21 amostras corretamente classificadas, 1 amostra classificada incorretamente como "fire" (falso positivo).
*   **Classe "fire":** 43 amostras corretamente classificadas, 3 amostras classificadas incorretamente como "no fire" (falso negativo).

### M√©tricas de Classifica√ß√£o
          precision    recall  f1-score   support

       0       0.88      0.95      0.91        22
       1       0.98      0.93      0.96        46

accuracy                           0.94        68


*   **Acur√°cia:** 94%
*   **Precis√£o:** 88% para "no fire" e 98% para "fire"
*   **Recall:** 95% para "no fire" e 93% para "fire"
*   **F1-score:** 91% para "no fire" e 96% para "fire"

### Curva ROC e AUC

![Curva ROC](assets/cnn_zero_roc_curve)

A curva ROC e o valor AUC indicam um excelente desempenho do modelo na discrimina√ß√£o entre as classes "fire" e "no fire". O valor de AUC de 0.95 para ambas as classes refor√ßa a capacidade do modelo de classificar corretamente as imagens.

### Conclus√£o

O modelo CNN treinado do zero alcan√ßou um alto desempenho, mas demonstrou sinais de overfitting. Para melhorar a generaliza√ß√£o, recomenda-se:

*   Aplicar data augmentation.
*   Adicionar camadas de Dropout ou BatchNormalization.
*   Ajustar o Early Stopping.

## Resultados da Transfer√™ncia de Aprendizado

### Vis√£o Geral

Este modelo utilizou Transfer√™ncia de Aprendizado com a arquitetura InceptionV3, pr√©-treinada no ImageNet, para classificar imagens em "fire" e "no fire".

### Desempenho Durante o Treinamento

O modelo demonstrou um desempenho muito bom desde o in√≠cio, com alta acur√°cia tanto no conjunto de treinamento quanto no de valida√ß√£o.

*   **Acur√°cia:** A acur√°cia no conjunto de treinamento subiu rapidamente, atingindo quase 100% ao final das √©pocas. A acur√°cia no conjunto de valida√ß√£o tamb√©m foi alta, oscilando em torno de 97-98%.
*   **Perda (Loss):** A perda no conjunto de treinamento diminuiu significativamente, enquanto a perda no conjunto de valida√ß√£o se manteve em n√≠veis baixos, indicando uma boa capacidade de generaliza√ß√£o.

### Gr√°ficos de Acur√°cia e Perda

![Acur√°cia por √©poca](assets/cnn_transferencia_acuracia_por_epoca)

*Este gr√°fico mostra a acur√°cia ao longo das √©pocas para os conjuntos de treinamento e valida√ß√£o.*

![Perda por √©poca](assets/cnn_transferencia_perda_por_epoca)

*Este gr√°fico exibe a perda (loss) ao longo das √©pocas para os conjuntos de treinamento e valida√ß√£o.*

### Matriz de Confus√£o

![Matriz de Confus√£o](assets/cnn_transferencia_matriz_confusao)

A matriz de confus√£o revela o seguinte:

*   **Classe "no fire":** 22 amostras corretamente classificadas, 0 amostras classificadas incorretamente.
*   **Classe "fire":** 46 amostras corretamente classificadas, 0 amostras classificadas incorretamente.

### M√©tricas de Classifica√ß√£o
          precision    recall  f1-score   support

       0       1.00      1.00      1.00        22
       1       1.00      1.00      1.00        46

accuracy                           1.00        68


*   **Acur√°cia:** 100%
*   **Precis√£o:** 100% para ambas as classes
*   **Recall:** 100% para ambas as classes
*   **F1-score:** 100% para ambas as classes

### Curva ROC e AUC

![Curva ROC](assets/cnn_transferencia_roc_curve)

A curva ROC e o valor AUC indicam um desempenho perfeito do modelo. O valor de AUC de 1.00 para ambas as classes demonstra a capacidade do modelo de classificar corretamente as imagens.

### Conclus√£o

O modelo de Transfer√™ncia de Aprendizado com InceptionV3 alcan√ßou um desempenho excepcional, com acur√°cia e outras m√©tricas perfeitas nos dados de teste. Isso sugere que a utiliza√ß√£o de uma arquitetura pr√©-treinada foi altamente eficaz para este problema de classifica√ß√£o.

# Interpreta√ß√£o do Fine-Tuning

Este documento traz a an√°lise dos resultados obtidos ap√≥s o fine-tuning do modelo de classifica√ß√£o de imagens de queimadas.

---

## 1. Vis√£o Geral do Treinamento

- **√âpocas previstas:** 50  
- **√âpocas executadas:** 11 (interrompido por EarlyStopping com `patience=10`)  
- **Tempo total de treinamento:** 1 min 44 s

---

## 2. M√©tricas por √âpoca

### 2.1 Acur√°cia por √âpoca  
![Acur√°cia por √©poca](docs/images/accuracy_per_epoch.png)  
- Treino: oscila entre 99.1 % e 99.7 %.  
- Valida√ß√£o: mant√©m-se em ~97.82 %, sem melhoria.

### 2.2 Perda por √âpoca  
![Perda por √©poca](docs/images/loss_per_epoch.png)  
- Treino: varia entre 0.3 e 1.3.  
- Valida√ß√£o: estabiliza em ~5.8, indicando poss√≠vel desajuste entre loss e accuracy.

---

## 3. Avalia√ß√£o no Conjunto de Teste

### 3.1 Matriz de Confus√£o  
![Matriz de Confus√£o](docs/images/confusion_matrix.png)  

### 3.2 Curva ROC  
![ROC Curve](docs/images/roc_curve.png)  

### 3.3 Relat√≥rio de Classifica√ß√£o

| Classe | Precision | Recall | F1-Score | Suporte |
|:------:|:---------:|:------:|:--------:|:-------:|
|   0    |   1.00    |  1.00  |   1.00   |   22    |
|   1    |   1.00    |  1.00  |   1.00   |   46    |
| **‚Äî**  |    ‚Äî      |   ‚Äî    |   ‚Äî      |   ‚Äî     |
| **Accuracy** |       ‚Äî       |   ‚Äî    | **1.00** |   68    |

> **Obs.:** Desempenho perfeito pode indicar conjunto pequeno ou overfitting.

---

## 4. Conclus√µes e Pr√≥ximos Passos

1. **Overfitting**:  
   - Validar com _data augmentation_ ou usar k-fold cross-validation.  
2. **Valida√ß√£o Estagnada**:  
   - Reavaliar _class weights_ ou normaliza√ß√£o das labels.  
3. **Callbacks**:  
   - Se quiser treinar as 50 √©pocas completas, remova ou aumente o `patience` do `EarlyStopping`.  
   - Ajustar `ReduceLROnPlateau` para resposta mais r√°pida (p.ex. `factor=0.1`, `patience=3`).  

# An√°lise Comparativa dos Modelos de Classifica√ß√£o de Imagens de Queimadas

## 1. Resumo dos Resultados

| Modelo                       | Acur√°cia | Precis√£o (Classe 0) | Recall (Classe 0) | F1-Score (Classe 0) | Precis√£o (Classe 1) | Recall (Classe 1) | F1-Score (Classe 1) |
| ---------------------------- | -------- | ------------------- | ----------------- | ------------------- | ------------------- | ----------------- | ------------------- |
| CNN Treinada do Zero         | 94%      | 88%                 | 95%               | 91%                 | 98%                 | 93%               | 96%                 |
| Transfer√™ncia de Aprendizado | 100%     | 100%                | 100%              | 100%                | 100%                | 100%              | 100%                |
| Fine-Tuning                  | 100%     | 100%                | 100%              | 100%                | 100%                | 100%              | 100%                |

## 2. An√°lise Detalhada

### 2.1. CNN Treinada do Zero

*   **Vantagens:**
    *   Modelo base para compara√ß√£o.
    *   Bom desempenho inicial com ajustes b√°sicos.
*   **Desvantagens:**
    *   Sinais de overfitting (alta acur√°cia no treino, menor na valida√ß√£o).
    *   Requer mais dados e ajustes para generalizar bem.
*   **Considera√ß√µes:**
    *   Apesar do bom desempenho, a diferen√ßa entre as m√©tricas de treino e valida√ß√£o sugere que o modelo est√° memorizando os dados de treino em vez de aprender padr√µes generaliz√°veis.

### 2.2. Transfer√™ncia de Aprendizado (InceptionV3)

*   **Vantagens:**
    *   Excelente desempenho com poucas √©pocas de treinamento.
    *   Alta capacidade de generaliza√ß√£o devido ao uso de conhecimento pr√©-existente.
*   **Desvantagens:**
    *   Pode ser excessivo para um problema relativamente simples.
    *   Requer mais recursos computacionais.
*   **Considera√ß√µes:**
    *   A Transfer√™ncia de Aprendizado se mostrou extremamente eficaz, atingindo acur√°cia perfeita nos dados de teste. Isso demonstra o poder de utilizar modelos pr√©-treinados em tarefas similares.

### 2.3. Fine-Tuning

*   **Vantagens:**
    *   Aproveita um modelo pr√©-treinado, ajustando-o para o problema espec√≠fico.
    *   Potencial para alta precis√£o com menos dados e tempo de treinamento.
*   **Desvantagens:**
    *   Requer ajuste cuidadoso dos hiperpar√¢metros para evitar overfitting.
    *   Pode ser interrompido prematuramente pelo EarlyStopping se a valida√ß√£o n√£o melhorar.
*   **Considera√ß√µes:**
    *   O Fine-Tuning alcan√ßou resultados semelhantes √† Transfer√™ncia de Aprendizado, mas com a necessidade de monitorar e ajustar os callbacks para garantir um treinamento adequado.

## 3. Conclus√£o Geral

*   A **Transfer√™ncia de Aprendizado** e o **Fine-Tuning** foram superiores √† CNN treinada do zero, atingindo acur√°cia perfeita nos dados de teste.
*   A escolha entre Transfer√™ncia de Aprendizado e Fine-Tuning depende dos recursos dispon√≠veis e da necessidade de ajustes finos no modelo.
*   Para a CNN treinada do zero, recomenda-se aplicar t√©cnicas de regulariza√ß√£o e aumentar a quantidade de dados para melhorar a generaliza√ß√£o.
*   √â importante monitorar os callbacks durante o treinamento (especialmente o EarlyStopping) para garantir que o modelo seja treinado adequadamente.

## 4. Pr√≥ximos Passos

*   **Data Augmentation:** Aplicar transforma√ß√µes nas imagens para aumentar a variabilidade dos dados de treinamento.
*   **Regulariza√ß√£o:** Adicionar camadas de Dropout ou BatchNormalization para reduzir o overfitting.
*   **Valida√ß√£o Cruzada:** Utilizar valida√ß√£o cruzada para obter uma estimativa mais robusta do desempenho do modelo.
*   **Ajuste de Hiperpar√¢metros:** Realizar uma busca mais detalhada pelos melhores hiperpar√¢metros para cada modelo.



## üìã Licen√ßa

<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><a property="dct:title" rel="cc:attributionURL" href="https://github.com/agodoi/template">MODELO GIT FIAP</a> por <a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://fiap.com.br">Fiap</a> est√° licenciado sobre <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">Attribution 4.0 International</a>.</p>
